# 주요 병목지점

![image.png](/.asset/sangjun121/week1-3-1.webp)

### 병목지점이란?

> 인프라 아키텍처 용어로서 병목 현상이란, **처리량을 제한하고 있는 지점**을 의미합니다.
> 

아래 문서는 성능의 문제 발생 시의 일어날 수 있는 간단한 시나리오와, 시스템의 주요 병목지점에 대해 공부하였습니다. 이후 JVM 기반 어플리케이션에서 발생 할 수 있는 병목지점에 대해 공부하고, 일반적인 성능개선 방안에 대해 간단히 기술하였습니다.

<br>

## 부하(WorkLoad)가 증가할 때, 발생할 수 있는 문제 상황

### 1. **응답 속도 (Latency) 저하**

- 가장 기본적으로 서버에 트래픽이 증가하는 경우, 클라이언트 응답 속도가 저하 될 수 있습니다. 웹시스템의 경우 WAS의 응답 외에도, AP서버와 DB서버 응답시간도 포함되기 때문에, 어느 지점에서 Latency가 길게 발생하는지 확인하는 것이 중요합니다.
- 응답 속도는 전체 서브시스템들의 Latency의 합계이기 때문에, 각 서브 시스템에서 캐시를 사용하거나, 서버의 트래픽을 분산하는 로드밸런싱, DB서버에서는 데이터베이스 최적화, WAS에서는 코드 최적화를 진행하여, 전체 응답 속도 (Latency)를 줄일 수 있습니다.

<br>

### 2. 시스템 LOCK의 비효율성

- **시스템 자원에는 동시성 제어가 필요한 공유 자원이 있습니다.** 여러 사용자가 동시에 해당 자원에 접근하려할 때, 데이터 일관성과 무결성을 유지하기 위해, 자원에 Lock을 사용합니다.
- 하지만 트래픽이 증가하는 상황에서 Lock이 걸려있는 경우, 다른 프로세스나 Thread는 해당 리소스에 접근할 수 없고 대기 상태로 들어가게 되어 시스템 성능이 저하될 수 있습니다.(아래 비관적 Lock 기법 사용시)
    
    ### Deadlock
    
    - Deadlock은 기본적으로, 두 개 이상의 트랜잭션이 서로 필요한 자원을 가지고 있으면서, 상대의 자원을 기다리며 무한 대기 상태에 빠지는 현상을 의미합니다. Deadlock은 컴파일 당시에 파악하기 어려우며, 배포 이후 감지되는 경우 큰 손실을 불러올 수 있습니다. 따라서, 데드락 감지 알고리즘과 적절한 테스트를 통해 사전에 감지하는 것이 중요합니다.
    - (Deadlock에 대한 운영체제 공부기록을 첨부합니다. [DeadLock이란?](https://www.notion.so/Chapter-6-868621de5d314f09aa642fa4c3a1af63?pvs=21))
    
    ### Long Lock
    
    - 특정 트랜젝션이 락을 오랫동안 유지하여 다른 트랜젝션의 자원 사용을 지체하게 만드는 것을 의미합니다. 이를 해결하기 위해, 트랜젝션을 가능한 짧게 유지하며, 필요한 락만 최소한으로 사용하는 것이 필요합니다.
    
    ### Lock Contention(락 경합)
    
    - 여러 트랜잭션이 동시에 같은 락을 요청할 때 발생하는 문제입니다. 락 경합을 줄이기 위해서 락의 범위를 최소화하고, 락의 수준을 조정하는 조치를 취할 수 있습니다.
    
    ### 비관적 LOCK (**pessimistic locking)**
    
    - 비관적 LOCK은 다른 프로세스나 스레드가 데이터나 자원을 변경하지 않도록 락을 걸고 기다리는 방식입니다. 즉 Lock이 걸려있는 동안 해당 자원에 다른 프로세스가 접근할 수 없습니다. 이로 인해 다른 프로세스들은 자원에 대한 대기시간이 늘어나고, 전체적인 시스템 성능의 저하를 유발합니다.

<br>

### 시스템 LOCK의 비효율성을 해결하기 위한 방안

- 위의 시스템 Lock 사용으로 인한 성능저하를 해결하기 위해서는, 가능한 Lock을 적게 사용하고 락의 사용범위를 줄여야 합니다. Lock 사용 기법은 다음과 같습니다.
    
    ### 낙관적 LOCK(**optimistic locking) 사용하기**
    
    - 낙관적 LOCK은 충돌이 발생하지 않는다고 낙관적으로 가정하는 기법입니다.
    - 해당 기법은 락을 걸지 않고 변경 요청이 있을 때, 실제 데이터가 변경되었는지만 검사합니다. 만약 다른 프로세스나 스레드가 데이터를 변경하는 경우, 이를 감지하고 변경되지 않았을 경우에만 데이터를 업데이트합니다.
    - 따라서, 트랜잭션을 커밋하는 최종 업데이트 과정에서만 락을 점유하기 때문에, 락 점유 시간을 최소화 하여 성능을 개선할 수 있습니다.

<br>

## 2. 주요 병목 지점

시스템을 3계층형으로 바라보았을 때, 발생할 수 있는 병목 지점은 아래와 같습니다. 

![image.png](/.asset/sangjun121/week1-3-2.png)

- 웹 서버 운영의 관점에서, 3계층형은 **프레젠테이션 계층 (Presentation Tier), 어플리케이션 계층 (Application Tier), 데이터 계층 (Data Tier)** 을 의미합니다.

<br>

### 1. CPU 병목

- CPU 사용률은 처리 효율성을 의미합니다. 따라서, CPU 사용률이 높을 수록 비효율적인 상태가 아닌, 다른 계층의 처리량이 매우 좋아 CPU를 최대한 많이 사용한다는 의미입니다. 따라서, CPU의 사용률이 매우 높아져 한계량에 가까워진다면, 시스템의 병목현상은 CPU에서 나타납니다.

- CPU 성능 문제의 원인은 다음과 같습니다.
    
    **대기 행렬의 병목현상**
    
    - CPU를 최대 사용률까지 사용하더라도, 대기 행렬이 줄어들지 않는 상황에서 CPU는 처리량(Throughput) 측면에서, 병목 지점이 될 수 있습니다.
    
    **해결방안**
    
    - 대규모 웹 시스템에서는 사용자 수에 맞춰 Scaling을 진행하여 처리량을 늘릴 수 있습니다.
    - 처리량을 증가시킨다고 하더라도, 처리시간 자체가 오래 걸린다면, 응답시간에는 큰 차이가 없습니다. 따라서 응답시간의 개선을 위해, 다수의 CPU에게 동시 분할 처리를 도입하는 방법이 있습니다.
    - I/O 비동기화 방법을 적용합니다. 기본적으로 I/O작업에 비해 CPU의 처리속도는 비약적으로 크기 때문에 I/O 비동기화를 사용한다면, 프로세스는 I/O작업 완료를 기다리지 않고 다음 작업을 진행 할 수 있습니다.

<br>

### 2. 메모리 병목

- 메모리에서 발생할 수 있는 병목 원인은 다음과 같습니다.
    
    **메모리 용량 한계에 따른 병목현상**
    
    - 프로세스는 기본적으로 메인 메모리 영역(RAM)에서 실행됩니다. 하지만 물리적 한계로 인해 메모리의 영역은 부족해지고, 한번에 실행할 수 있는 프로세스의 수는 제한이 됩니다. 이와 같은 문제를 해결하고자, 하드디스크의 일부 영역을 사용한 가상 메모리(Virtual Memory)로 확장하여 더 많은 프로세스를 실행시킬 수 있게 되었습니다.
    - 하지만, 하드디스크는 CPU에 비해 압도적으로 성능이 낮기 때문에, 두 하드웨어 간의 성능차이로 전체적인 시스템의 성능 저하가 발생하게 됩니다.
    
    **메모리 위, 공유 영역의 동일 데이터 접근으로 인한 병목 현상**
    
    - 기본적으로 메모리 위의 캐시는 여러 프로세스가 공유할 수 있습니다. 단일 프로세스 내부 Thread들도 메모리 영역 내에 공유하는 부분이 생기는데, 이를 참조하고 쓰기 할 때, 관리할 필요성이 생겨 성능저하 문제를 일으키게 됩니다.

<br>

### 3. 네트워크 I/O의 병목

- 네트워크에서 발생할 수 있는 병목 원인은 다음과 같습니다.
    
    **통신 프로세스 안에서의 병목현상**
    
    - 네트워크 통신 작업에는 데이터 전송, 통신결과 확인이라는 과정이 반드시 수행되기 때문에, 네트워크의 대역폭이 크다고 하더라도 처리하는 프로세스가 하나라면 높은 처리량은 기대하기 힘듭니다.
    
    **해결방안**
    
    - 그래도 높은 대역폭은 통신 속도를 증가시켜주기 때문에, 처리를 다중화하여, 대역폭을 모두 사용하는 것이 중요합니다.
    - 통신 간의 자원을 압축하여 전송량을 줄이는 방법이 있습니다. 하지만 압축의 경우 이를 전송받고 처리하는 CPU에 오버헤드가 발생하게 됩니다.
    
<br>

## 3. JVM 어플리케이션 내 주요 병목지점

- 위의 주요 병목 현상들 외에도, 어플리케이션에서 발생하는 병목지점이 존재합니다. JVM 기반 어플리케이션 성능개선이라는 주제에 알맞게 JVM 기반 어플리케이션에서 발생할 수 있는 주요 병목지점을 아래 작성하였습니다.

<br>

### 1. **Garbage Collection (GC)**

---

**Garbage Collection (GC)은 JAVA 어플리케이션 구동시 Heap 영역에서 사용되지 않는 객체를 청소하여 메모리를 확보하는 작업을 의미합니다.** C/C++과 같은 언어는 메모리 할당 및 해제를 직접 수행하지만, JAVA기반 어플리케이션에서는 GC가 사용하지 않은 객체에 대해 메모리 해제를 대신 관리합니다.

이러한 GC에서 성능저하가 발생하는 이유는, **GC가 자주 수행 되는 경우 STW로 인하여 애플리케이션의 성능이 저하될 수 있기 때문입니다**. 이제 Java의 GC의 작동원리를 살펴보며, 어느 성능 저하가 발생하는 원인에 대해 작성하겠습니다. (Garbage Collection의 작업 방식과 구체적인 튜닝법은 추후 작성 예정입니다. 현재 문서에서는 성능저하가 발생하는 원인분석을 목표로 작성되었습니다.)

**JAVA 어플리케이션은 Garbage Collection를 실행할 때, Garbage Collection를 위한 Thread를 제외하고 이외 모든 Thread를 정지 시킵니다.** 이후 Garbage Collection의 작업이 모두 끝난 이후에나 다시 Thread가 실행상태로 돌아가는데, 중간의 이 **대기시간을 STW(Stop the World)**라고 부릅니다. 이로 인해 어플리케이션 성능은 떨어지기 때문에, 시스템의 CPU 코어 수나 메모리의 크기에 맞는 적절한 GC 방식을 결정하는 것이 중요합니다.

![image.png](/.asset/sangjun121/week1-3-3.png)

먼저 JAVA에서는 Heap 영역에 객체가 할당되는데, 처음 할당된 객체는 Young Generation 영역의 Eden으로 들어갑니다. 이후 Eden 영역의 메모리가 꽉차게 되면, Survivor1 혹은 Survivor2로 이동합니다. 그리고 Young 영역에서 오래동안 살아남은 객체들은, Old 영역으로 이동합니다.

해당 영역들을 기준으로 GC의 종류는 2가지로 나뉩니다. 

1. **Major GC (Full GC)**
    - Old 영역이 가득찬 경우에, 객체의 메모리를 해제합니다. Old 영역이 Young영역보다 메모리의 크기가 크기 때문에, Major GC는 상대적으로 적게 일어납니다.
2. **Minor GC**
    - Eden 영역이 꽉찬 경우에 발생합니다. Major GC에 비해 속도가 빠르고 빈번하게 일어납니다. 결국 빈번한 GC와 객체의 이동과정에서 어플리케이션 병목이 발생합니다.

결론적으로 성능 개선을 위해서, **Major, Minor GC를 처리하는 알고리즘(GC 방식 5가지)과 메모리 사용량을 고려한 GC튜닝**의 목표를 설정해야 합니다.

<br>

### **2. 스레드 동기화 및 경쟁 (Thread Synchronization and Contention)**

---

**다수의 실행 Thread들로 인한, Context Switching**

JAVA의 멀티스레딩은 실행 단위인 Thread를 여러 개 사용하여 어플리케이션의 여러 작업을 동시에 수행할 수 있게 합니다. 이런 동시 작업은 어플리케이션의 성능을 늘려주지만, CPU의 실행 Thread를 변경하는 컨택스트 스위칭(Context Switching)으로 인해 오버헤드가 발생 할 수 있습니다. 따라서 Thread의 수를 적절히 관리하는 것이 중요합니다.

**공유자원에 대한 Thread들의 경쟁 및 동기화**

JAVA에서 synchronized 키워드를 사용하면, 해당 코드 블럭에 대해 한 Thread만 접근 가능하게 동기화 할 수 있습니다. 이때, 동기화된 코드에 접근하려는 Thread들이 대기하면서, 처리 속도가 느려지거나 Deadlock이 발생 할 수 있습니다. 

**해결방안1. Lock Free 알고리즘**

- **Lock Free 알고리즘이란, 다중 스레드 환경에서 Lock을 사용하지 않고 Atomic 연산을 사용하여, 데이터의 동시성을 안전하게 관리하는 알고리즘입니다. Lock을 사용하지 않기에, 병목현상을 줄이고 성능 향상에 중점을 둡니다.**

    **Atomic 연산이란?**

    Atomic 연산은 중간에 중단되거나 다른 작업에 의해 간섭받지 않고 한 번에 완료되는 연산을 의미합니다.


    **원칙**

    - 특정 작업을 동시에 여러 스레드가 호출했을 때, 최소 하나의 스레드 작업이 완료해서 반환되어야 합니다.
    - 즉, Thread가 무기한 대기 상태에 빠지는 것을 방지하고, 모든 스레드가 일정 시간 내에 작업을 완료 할 수 있도록 합니다.
      

    **장점**

    - Deadlock, Livelock, 우선순위 역전과 같은 문제를 해결할 수 있습니다.
    - Lock을 사용하지 않아, 컨텍스트 스위칭과 같은 CPU오버헤드를 줄일 수 있습니다.

<br>

**해결방안2. Concurrent Collections 사용**

- **Concurrent Collections이란**, 멀티스레드 환경의 **일반적인 컬렉션(List, Dictionary)에서** 발생할 수 있는 데이터 경합 문제를 방지하기 위해 고안된 자료구조 집합입니다. 해당 자료구조를 이용하면, Lock 없이도 동시성 문제를 해결할 수 있습니다.

    **종류**

    Concurrent Collections에 해당하는 자료구조는 다음과 같습니다.

    1. **Concurrent Queue**
    2. **Concurrent Stack**
    3. **Concurrent Dictionary**
    4. **Concurrent Set**
    5. **Blocking Collections**


    **장점**

    - Lock을 최소화 하거나 없이도 안전하게 동작하도록 설계되어, 다중 스레드 환경에서도 데이터의 일관성을 유지 할 수 있습니다. 덕분에, Lock으로 인한 성능저하 문제를 해결 할 수 있습니다.

<br>

### 참고 래퍼런스

[GC(Garbage Collection)가 자주 발생하면 왜 안좋을까?](https://velog.io/@yht0827/gc)      
[성능 향상을 위한 인프라 구조](https://slog2.tistory.com/29)
